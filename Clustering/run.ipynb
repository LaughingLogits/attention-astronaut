{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bcf1224-40eb-48cd-b528-b2f7dfdad584",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir Database #Only run once, makes a folder where the h5py database is saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b332fe4-996d-4f54-922e-8355caed189b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#This is required to import the APMAE model from the other directory\n",
    "import sys, os\n",
    "path2add = os.path.normpath(os.path.abspath(os.path.join(os.path.dirname('./run.ipynb'), os.path.pardir, 'Model')))\n",
    "if (not (path2add in sys.path)) :\n",
    "    sys.path.append(path2add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7c11b6-fcfd-4bf4-a49e-c050ab8566ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Our code\n",
    "from DataUtil.DataLoader import IterableAttentionLoader\n",
    "from DataUtil.AttentionData import AttentionData\n",
    "from ap_mae import APMAE\n",
    "\n",
    "#Imported packages\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "#We recommend to use the cuml package for quicker computation if a decent gpu is available, can be replaced by the corresponding sklearn packages\n",
    "from cuml import UMAP\n",
    "from cuml import HDBSCAN\n",
    "from cuml.metrics.pairwise_distances import pairwise_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635abcfe-6dec-4a0d-a1a6-854bfaf52684",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd95bfb6-94dd-4373-8011-f81f1bb10fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = '3B' #Set the size of the target model here. 3B, 7B or 15B\n",
    "            #3B requires 2TB of storage\n",
    "            #7B requires 3.5TB of storage\n",
    "            #15B requires 5.5TB of storage\n",
    "\n",
    "db_name = \"reproduction_{}\".format(size)\n",
    "target_model_name = 'bigcode/starcoder2-{}'.format(size.lower())\n",
    "encoding_model_name = 'LaughingLogits/AP-MAE-SC2-{}'.format(size)\n",
    "dataset_name = 'LaughingLogits/Stackless_Java_V2'\n",
    "split = 'test'\n",
    "\n",
    "device = 'cpu'\n",
    "languages = ['java']\n",
    "\n",
    "understanding = [\"identifiers\"]\n",
    "literals = [\"boolean_literals\", \"string_literals\", \"numeric_literals\"]\n",
    "operators = ['boolean_operators', 'mathematical_operators', 'assignment_operators']\n",
    "syntax = ['eol', 'closing_bracket']\n",
    "tasks = [\"random\"] + understanding + literals + operators + syntax\n",
    "\n",
    "samples_per_task = 1000\n",
    "context_length = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd044f9b-ddad-4460-abf0-7f0c9afd25c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# These can be replaced with a list of keys, but we used all values in our investigation\n",
    "# e.g. incorrect java predicitions for the eol task, all heads from layer 4 and 7\n",
    "# langs = ['java']\n",
    "# corrects = ['incorrect']\n",
    "# querys = ['eol']\n",
    "# layers = ['4','7']\n",
    "# heads = \"*\"\n",
    "langs = \"*\"\n",
    "corrects = \"*\"\n",
    "querys = \"*\"\n",
    "layers = \"*\"\n",
    "heads = \"*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775a3422-edcf-4433-bcb3-bb5c739a15ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_model = AutoModelForCausalLM.from_pretrained(target_model_name, device_map=\"auto\")\n",
    "encoding_model = APMAE.from_pretrained(pretrained_model_name_or_path=encoding_model_name)\n",
    "attention_data = AttentionData(target_model.config, tasks, languages, db_name)\n",
    "attention_loader = IterableAttentionLoader(dataset_name, samples_per_task, context_length, tasks, languages[0], target_model_name, False, target_model, device, split, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e7edac-1db1-4ee6-8710-0804b0a5f1cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Generate patterns and encode - Section 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853ca6d3-e88e-4bdc-8fb3-98c009288c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_data.generate_patterns(attention_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bdfa23-968b-4721-bad4-6934b5b17c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_data.encode(encoding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fcb7a0-6ff5-4aeb-ba60-f08a1f40bc9e",
   "metadata": {},
   "source": [
    "# UMAP - Section 5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73494749-485e-4746-969f-6bf02cbd39e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = attention_data.data.get_grouped_samples(langs, corrects, querys, layers, heads, 'enc_cls')\n",
    "X_reduced = UMAP(n_components=4, min_dist=0, metric = 'manhattan').fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c0087c-88a6-4427-889d-897c3fcbe26c",
   "metadata": {},
   "source": [
    "# HDBSCAN - Section 5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d9056e-490c-4aa6-8f06-dbf890f22ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdb = HDBSCAN(cluster_selection_epsilon=0.5)\n",
    "y_hdb = hdb.fit_predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703f1732-c23e-4e1c-9087-ba6bff652cfe",
   "metadata": {},
   "source": [
    "# Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b690150f-3fdc-489d-8fd7-4c95015b618d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_size(size):\n",
    "    if size == '3B':\n",
    "        return 100\n",
    "    if size == '7B':\n",
    "        return 167\n",
    "    if size == '15B':\n",
    "        return 260\n",
    "\n",
    "def inner_cluster_distances(X, clusters):\n",
    "    dist = []\n",
    "    c = Counter(clusters)\n",
    "    remove = [x[0] for x in c.items() if x[1] < get_min_size(size)]\n",
    "    remove.append(-1)\n",
    "    cluster_ids = np.unique(clusters)\n",
    "    cluster_ids = [x for x in cluster_ids if x not in remove]\n",
    "    for c in tqdm(np.unique(cluster_ids)):\n",
    "        d = X[clusters == c]\n",
    "        # if len(d) > 100000: #If you run out of memory this will save a lot\n",
    "        #     d = d[0::10]\n",
    "        distances = pairwise_distances(d)\n",
    "        distances = distances[np.triu_indices(distances.shape[0])]\n",
    "        dist.append((c,np.mean(distances)))\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10adc7f9-4047-4848-a732-a753cb81a23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = y_hdb\n",
    "c = Counter(clusters)\n",
    "\n",
    "dist = inner_cluster_distances(X_reduced, clusters)\n",
    "\n",
    "remove = [x[0] for x in c.items() if x[1] < get_min_size(size)]\n",
    "remove.extend([x[0] for x in dist if x[1] > 1])\n",
    "remove.append(-1)\n",
    "\n",
    "clusters = np.array([-1 if x in remove else x for x in clusters])\n",
    "clusters = clusters.reshape((len(clusters),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26aaf257-2904-4a57-8bb5-19f563aa8393",
   "metadata": {},
   "source": [
    "# Save to h5py database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3240edbb-643d-4c86-bb02-7a5ae96b7ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_data.data.write_grouped_samples(langs, corrects, querys, layers, heads, \"class_cls\", clusters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
