# When copying the link from the paper, some OS/pdf viewer combinations seem to insert spaces into the link, clickable links to the Huggingface dataset and model collection are listed here.

# Automated Attention Pattern Discovery at Scale in Large Language Models

This is the *reproduction package* for the paper entitled **Automated Attention Pattern Discovery at Scale in Large Language Models** with submission ID **13927** for AAAI-25. 

The repository is structured into three main directories:
- **Clustering**
-  **Dataset**
-  **Model** 

The [**Clustering**](./Clustering) directory comprises all the code for clustering attention heads and visualizing these clusters. This code corresponds to Section 5 of the paper. 

The [**Dataset**](./Dataset) directory comprises all the code for creating the dataset. This includes scraping GitHub repositories, extracting code files, removing autogenerated files, and removing exact- and near-duplicates between our custom dataset and Java-Stack v2. This code corresponds to Section 3 of the paper. 

The [**Model**](./Model) directory comprises all the code for building the *AP-MAE* model. This includes the model architecture and the training setup. This code corresponds to Section 4 of the paper. 

For further instructions on running the code, please refer to the README files in each directory. 

We also add more visualizations similar to Figure 10 in [**Visualization**](./Visualization). For each SC2 size, we show a plot for every task, split between correct and incorrect.

# Links

We release the StackLessV2 Java dataset [here](https://huggingface.co/datasets/LaughingLogits/Stackless_Java_V2).

We release the AP-MAE model collection [here](https://huggingface.co/collections/LaughingLogits/ap-mae-models-66b27a73536bb1306d55c4c4).
